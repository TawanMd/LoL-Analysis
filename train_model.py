"""
Script para treinar o modelo de predi√ß√£o de vit√≥ria do League of Legends
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from data_manager import load_data


def prepare_features(df):
    """
    Prepara as features para o modelo baseado nos dados dispon√≠veis.
    
    Args:
        df: DataFrame com os dados do jogo
        
    Returns:
        X: Features para treino
        y: Target (blueWins)
        feature_names: Lista com nomes das features
    """
    # Features relacionadas ao time azul que s√£o boas preditoras aos 10 minutos
    feature_columns = [
        'blueGoldDiff',           # Diferen√ßa de ouro
        'blueExperienceDiff',     # Diferen√ßa de experi√™ncia
        'blueKills',              # Abates do time azul
        'blueDeaths',             # Mortes do time azul
        'blueAssists',            # Assist√™ncias do time azul
        'blueDragons',            # Drag√µes do time azul
        'blueHeralds',            # Arautos do time azul
        'blueTowersDestroyed',    # Torres destru√≠das pelo time azul
        'blueFirstBlood',         # First blood do time azul
        'blueCSPerMin',           # CS por minuto do time azul
        'blueGoldPerMin',         # Ouro por minuto do time azul
    ]
    
    # Verifica quais features est√£o dispon√≠veis no dataset
    available_features = [col for col in feature_columns if col in df.columns]
    
    print(f"Features dispon√≠veis: {available_features}")
    
    # Se n√£o tivermos todas as features esperadas, vamos usar as b√°sicas
    if len(available_features) < 5:
        # Features m√≠nimas que sabemos que existem
        available_features = [
            'blueGoldDiff',
            'blueExperienceDiff',
            'blueKills',
            'blueDragons',
            'blueFirstBlood'
        ]
    
    X = df[available_features].copy()
    y = df['blueWins'].copy()
    
    return X, y, available_features


def train_model(X, y, feature_names):
    """
    Treina um modelo Random Forest para prever vit√≥rias.
    
    Args:
        X: Features
        y: Target
        feature_names: Nomes das features
        
    Returns:
        model: Modelo treinado
        scaler: Scaler usado para normaliza√ß√£o
        metrics: M√©tricas de avalia√ß√£o
    """
    # Divide os dados em treino e teste
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Normaliza as features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Cria e treina o modelo
    print("Treinando o modelo Random Forest...")
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    
    model.fit(X_train_scaled, y_train)
    
    # Faz predi√ß√µes
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)
    
    # Calcula m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    
    print(f"\nAcur√°cia no conjunto de teste: {accuracy:.4f}")
    print(f"Acur√°cia m√©dia (cross-validation): {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    
    # Relat√≥rio de classifica√ß√£o
    print("\nRelat√≥rio de Classifica√ß√£o:")
    print(classification_report(y_test, y_pred, target_names=['Derrota', 'Vit√≥ria']))
    
    # Import√¢ncia das features
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nImport√¢ncia das Features:")
    print(feature_importance)
    
    # Plota a import√¢ncia das features
    plt.figure(figsize=(10, 6))
    sns.barplot(data=feature_importance, x='importance', y='feature')
    plt.title('Import√¢ncia das Features no Modelo')
    plt.xlabel('Import√¢ncia')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    plt.close()
    
    # Matriz de confus√£o
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matriz de Confus√£o')
    plt.ylabel('Valor Real')
    plt.xlabel('Valor Predito')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png')
    plt.close()
    
    metrics = {
        'accuracy': accuracy,
        'cv_scores': cv_scores,
        'feature_importance': feature_importance,
        'confusion_matrix': cm
    }
    
    return model, scaler, metrics


def save_model_components(model, scaler, feature_names, filename='lol_win_predictor.joblib'):
    """
    Salva o modelo, scaler e nomes das features em um √∫nico arquivo.
    """
    # Cria um dicion√°rio com todos os componentes
    model_data = {
        'model': model,
        'scaler': scaler,
        'feature_names': feature_names,
        'version': '1.0'
    }
    
    # Salva tudo em um √∫nico arquivo
    joblib.dump(model_data, filename)
    print(f"Modelo salvo como '{filename}'")


def main():
    """Fun√ß√£o principal para treinar e salvar o modelo"""
    
    print("=== Treinamento do Modelo de Predi√ß√£o LoL ===\n")
    
    # Carrega os dados
    print("Carregando dados...")
    df = load_data()
    print(f"Total de partidas carregadas: {len(df):,}")
    
    # Prepara as features
    X, y, feature_names = prepare_features(df)
    print(f"\nShape dos dados: X={X.shape}, y={y.shape}")
    print(f"Distribui√ß√£o do target: {y.value_counts().to_dict()}")
    
    # Treina o modelo
    model, scaler, metrics = train_model(X, y, feature_names)
    
    # Salva o modelo e componentes
    print("\nSalvando o modelo...")
    save_model_components(model, scaler, feature_names)
    
    # Salva informa√ß√µes sobre o modelo
    model_info = {
        'features': feature_names,
        'accuracy': metrics['accuracy'],
        'cv_scores_mean': metrics['cv_scores'].mean(),
        'cv_scores_std': metrics['cv_scores'].std()
    }
    
    with open('model_info.txt', 'w') as f:
        f.write("=== Informa√ß√µes do Modelo ===\n\n")
        f.write(f"Features utilizadas: {', '.join(feature_names)}\n")
        f.write(f"Acur√°cia no teste: {model_info['accuracy']:.4f}\n")
        f.write(f"Acur√°cia CV: {model_info['cv_scores_mean']:.4f} (+/- {model_info['cv_scores_std'] * 2:.4f})\n")
        f.write("\nImport√¢ncia das Features:\n")
        f.write(metrics['feature_importance'].to_string())
    
    print("\n‚úÖ Treinamento conclu√≠do com sucesso!")
    print("üìä Gr√°ficos salvos: feature_importance.png, confusion_matrix.png")
    print("üìÑ Informa√ß√µes do modelo salvas em: model_info.txt")
    
    # Teste r√°pido do modelo
    print("\n=== Teste R√°pido do Modelo ===")
    test_data = pd.DataFrame({
        'blueGoldDiff': [1000],
        'blueExperienceDiff': [500],
        'blueKills': [5],
        'blueDragons': [1],
        'blueFirstBlood': [1]
    })
    
    # Adiciona features faltantes se necess√°rio
    for feature in feature_names:
        if feature not in test_data.columns:
            test_data[feature] = 0
    
    # Reordena as colunas para corresponder ao treino
    test_data = test_data[feature_names]
    
    # Faz a predi√ß√£o usando o scaler e o modelo
    test_data_scaled = scaler.transform(test_data)
    prob = model.predict_proba(test_data_scaled)[0]
    
    print(f"\nExemplo de predi√ß√£o:")
    print(f"Entrada: {test_data.iloc[0].to_dict()}")
    print(f"Probabilidade de vit√≥ria do time azul: {prob[1]:.2%}")


if __name__ == "__main__":
    main()